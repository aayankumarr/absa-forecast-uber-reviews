{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "from transformers import BertTokenizerFast\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import BertForTokenClassification, BertTokenizerFast\n",
    "from transformers import get_scheduler\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aspect Seed Expansion Using Word2Vec."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train In-Domain Word2Vec on Uber Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In-Domain Dataset Size\n",
    "\n",
    "Smaller datasets are more prone to overfitting and noise with large embedding sizes.\n",
    "\n",
    "100 dimensions is a balanced tradeoff:\n",
    "\n",
    "Enough to capture meaning\n",
    "\n",
    "Not too high to overfit or produce noisy vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"uber_reviews_without_reviewid.csv\")\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    return re.findall(r\"\\w+\", str(text).lower())\n",
    "\n",
    "sentences = df[\"content\"].dropna().apply(tokenize).tolist()\n",
    "\n",
    "# Training Word2Vec\n",
    "w2v_model = Word2Vec(\n",
    "    sentences,\n",
    "    vector_size=200, \n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    workers=4,\n",
    "    sg=1  \n",
    ")\n",
    "\n",
    "\n",
    "w2v_model.save(\"uber_reviews_word2vec.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userName</th>\n",
       "      <th>userImage</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>repliedAt</th>\n",
       "      <th>appVersion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Good</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>2024-12-18 17:17:19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.556.10005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>User_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nice</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>2024-12-18 17:17:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.556.10005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>User_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Very convenient</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.532.10001</td>\n",
       "      <td>2024-12-18 17:09:42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.532.10001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>User_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Good</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>2024-12-18 17:08:27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.556.10005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>User_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>exllence</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>2024-12-18 17:08:16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.556.10005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>User_11995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Excellent!!!</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.553.10000</td>\n",
       "      <td>2024-11-24 21:59:16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.553.10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>User_11996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Worst experience after 10pm in Hyde cityno aut...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.552.10000</td>\n",
       "      <td>2024-11-24 21:56:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.552.10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>User_11997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Exceptional</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.552.10000</td>\n",
       "      <td>2024-11-24 21:52:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.552.10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>User_11998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Good Service.</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.553.10000</td>\n",
       "      <td>2024-11-24 21:50:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.553.10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>User_11999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Very bad experience with this app, booked a sh...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-24 21:44:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userName  userImage  \\\n",
       "0          User_0        NaN   \n",
       "1          User_1        NaN   \n",
       "2          User_2        NaN   \n",
       "3          User_3        NaN   \n",
       "4          User_4        NaN   \n",
       "...           ...        ...   \n",
       "11995  User_11995        NaN   \n",
       "11996  User_11996        NaN   \n",
       "11997  User_11997        NaN   \n",
       "11998  User_11998        NaN   \n",
       "11999  User_11999        NaN   \n",
       "\n",
       "                                                 content  score  \\\n",
       "0                                                   Good      5   \n",
       "1                                                   Nice      5   \n",
       "2                                        Very convenient      5   \n",
       "3                                                   Good      4   \n",
       "4                                               exllence      5   \n",
       "...                                                  ...    ...   \n",
       "11995                                       Excellent!!!      5   \n",
       "11996  Worst experience after 10pm in Hyde cityno aut...      5   \n",
       "11997                                        Exceptional      5   \n",
       "11998                                      Good Service.      5   \n",
       "11999  Very bad experience with this app, booked a sh...      1   \n",
       "\n",
       "       thumbsUpCount reviewCreatedVersion                   at replyContent  \\\n",
       "0                  0          4.556.10005  2024-12-18 17:17:19          NaN   \n",
       "1                  0          4.556.10005  2024-12-18 17:17:17          NaN   \n",
       "2                  0          4.532.10001  2024-12-18 17:09:42          NaN   \n",
       "3                  0          4.556.10005  2024-12-18 17:08:27          NaN   \n",
       "4                  0          4.556.10005  2024-12-18 17:08:16          NaN   \n",
       "...              ...                  ...                  ...          ...   \n",
       "11995              0          4.553.10000  2024-11-24 21:59:16          NaN   \n",
       "11996              0          4.552.10000  2024-11-24 21:56:10          NaN   \n",
       "11997              0          4.552.10000  2024-11-24 21:52:21          NaN   \n",
       "11998              0          4.553.10000  2024-11-24 21:50:30          NaN   \n",
       "11999              0                  NaN  2024-11-24 21:44:44          NaN   \n",
       "\n",
       "      repliedAt   appVersion  \n",
       "0           NaN  4.556.10005  \n",
       "1           NaN  4.556.10005  \n",
       "2           NaN  4.532.10001  \n",
       "3           NaN  4.556.10005  \n",
       "4           NaN  4.556.10005  \n",
       "...         ...          ...  \n",
       "11995       NaN  4.553.10000  \n",
       "11996       NaN  4.552.10000  \n",
       "11997       NaN  4.552.10000  \n",
       "11998       NaN  4.553.10000  \n",
       "11999       NaN          NaN  \n",
       "\n",
       "[12000 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expand Aspect Seeds Using the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.8/12.8 MB 8.5 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 11.2 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 4.5/12.8 MB 10.0 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 4.7/12.8 MB 8.9 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 4.7/12.8 MB 8.9 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 5.0/12.8 MB 4.4 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 5.3 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.9/12.8 MB 6.2 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 6.4 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.5/12.8 MB 6.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 6.1 MB/s eta 0:00:00\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USING SPACY FOR POS -TAGGING AND DEFINING ASPECT SEEDS BASED ON THE MOST FREQUENTLY USED ASPECTS \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "w2v_model = Word2Vec.load(\"uber_reviews_word2vec.model\")\n",
    "\n",
    "aspect_seeds = [\n",
    "    \"driver\", \"ride\", \"app\", \"fare\", \"support\", \"payment\",\n",
    "    \"booking\",  \"car\", \"interface\", \"service\",\n",
    "    \"map\", \"location\", \"tracking\", \"navigation\", \"speed\",\n",
    "     \"refund\", \"issue\", \"experience\",\n",
    "    \"agent\", \"customer\", \"drop\", \"pickup\", \"wallet\", \"route\",\n",
    "    \"destination\", \"delay\", \"wait\",\"uber\"\n",
    "]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_noun(word):\n",
    "    doc = nlp(word)\n",
    "    return len(doc) > 0 and doc[0].pos_ == \"NOUN\"\n",
    "\n",
    "def is_valid_word(word):\n",
    "    return word.isalpha() and word not in stop_words and is_noun(word)\n",
    "\n",
    "def gap_cutoff_filter(similar_list, drop_threshold=0.05):\n",
    "    filtered = []\n",
    "    for i in range(1, len(similar_list)):\n",
    "        if similar_list[i-1][1] - similar_list[i][1] > drop_threshold:\n",
    "            return similar_list[:i]\n",
    "    return similar_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USING COSINE SIMILARITY WITH A SIMILARITY THRESHOLD OF >0.75 TO MAP WORDS TO SIMILAR ASPECTS BASED ON THE DEFINED ASPECT SEEDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_words_map = defaultdict(list)\n",
    "similarity_threshold = 0.75\n",
    "topn = 10\n",
    "\n",
    "for seed in aspect_seeds:\n",
    "    if seed not in w2v_model.wv:\n",
    "        continue\n",
    "    similar_raw = w2v_model.wv.most_similar(seed, topn=topn)\n",
    "    filtered = [(w, s) for w, s in similar_raw if s >= similarity_threshold and is_valid_word(w)]\n",
    "    filtered = gap_cutoff_filter(filtered)\n",
    "    similar_words_map[seed] = filtered\n",
    "\n",
    "rows = []\n",
    "for seed, pairs in similar_words_map.items():\n",
    "    for word, sim in pairs:\n",
    "        rows.append({\"aspect_seed\": seed, \"similar_word\": word, \"similarity\": sim})\n",
    "\n",
    "expanded_df = pd.DataFrame(rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DRIVER → ['car (0.845)', 'man (0.811)', 'trip (0.805)', 'he (0.804)', 'drive (0.803)', 'luggage (0.797)', 'ride (0.785)', 'came (0.785)', 'person (0.782)', 'pickup (0.781)']\n",
      "\n",
      "RIDE → ['trip (0.898)', 'coming (0.816)', 'night (0.815)', 'bike (0.815)', 'once (0.814)', 'arrival (0.814)', 'completing (0.812)', 'confirmation (0.809)', 'accepted (0.808)', 'confirm (0.807)']\n",
      "\n",
      "APP → ['application (0.833)', 'system (0.73)', 'books (0.722)', 'platform (0.721)', 'diver (0.719)', 'company (0.717)', 'ever (0.717)', 'install (0.717)', 'trust (0.712)', 'seen (0.712)']\n",
      "\n",
      "FARE → ['shown (0.951)', 'reaching (0.935)', 'booking (0.93)', 'increased (0.928)', 'fair (0.925)', 'shows (0.924)', 'double (0.923)', 'showing (0.923)', 'increase (0.919)', 'different (0.918)']\n",
      "\n",
      "SUPPORT → ['chat (0.918)', 'team (0.908)', 'contact (0.907)', 'proper (0.894)', 'help (0.891)', 'care (0.887)', 'customer (0.881)', 'number (0.874)', 'ai (0.873)', 'mail (0.865)']\n",
      "\n",
      "PAYMENT → ['upi (0.927)', 'method (0.893)', 'cash (0.891)', 'online (0.871)', 'mode (0.856)', 'wallet (0.852)', 'add (0.814)', 'pending (0.807)', 'digital (0.801)', 'fraud (0.795)']\n",
      "\n",
      "BOOKING → ['fare (0.93)', 'increase (0.92)', 'shows (0.919)', 'while (0.91)', 'reaching (0.905)', 'shown (0.899)', 'changes (0.898)', 'fair (0.893)', 'increased (0.892)', 'initially (0.885)']\n",
      "\n",
      "CAR → ['drove (0.931)', 'safely (0.926)', 'man (0.919)', 'conversation (0.911)', 'helped (0.908)', 'luggage (0.907)', 'person (0.907)', 'guy (0.906)', 'gentleman (0.905)', 'music (0.904)']\n",
      "\n",
      "INTERFACE → ['seamless (0.982)', 'dependable (0.98)', 'smart (0.974)', 'timing (0.97)', 'verry (0.968)', 'perfect (0.967)', 'skills (0.963)', 'travel (0.963)', 'provider (0.963)', 'n (0.957)']\n",
      "\n",
      "SERVICE → ['experience (0.847)', 'application (0.83)', 'extremely (0.813)', 'behavior (0.812)', 'travel (0.81)', 'navigation (0.801)', 'services (0.799)', 'value (0.796)', 'smart (0.794)', 'such (0.794)']\n",
      "\n",
      "MAP → ['exact (0.916)', 'follow (0.916)', 'mobile (0.914)', 'properly (0.913)', 'puts (0.912)', 'picking (0.912)', 'locations (0.908)', 'mine (0.907)', 'completely (0.907)', 'directions (0.906)']\n",
      "\n",
      "LOCATION → ['drop (0.928)', 'spot (0.875)', 'wrong (0.872)', 'correct (0.872)', 'pickup (0.869)', 'map (0.861)', 'come (0.856)', 'destination (0.847)', 'place (0.834)', 'end (0.834)']\n",
      "\n",
      "TRACKING → ['anybody (0.989)', 'incredibly (0.988)', 'persons (0.986)', 'shift (0.984)', 'list (0.984)', 'truly (0.984)', 'facility (0.984)', 'join (0.984)', 'dissatisfied (0.984)', 'cheapest (0.983)']\n",
      "\n",
      "NAVIGATION → ['platform (0.975)', 'providing (0.974)', 'l (0.973)', 'anytime (0.972)', 'transport (0.971)', 'meet (0.969)', 'cheapest (0.967)', 'simple (0.966)', 'smell (0.966)', 'careful (0.966)']\n",
      "\n",
      "SPEED → ['receives (0.993)', 'america (0.993)', 'silly (0.993)', 'controls (0.993)', 'potential (0.992)', 'toyota (0.992)', 'hotel (0.992)', 'xx (0.992)', 'delays (0.992)', 'bristol (0.992)']\n",
      "\n",
      "REFUND → ['credit (0.951)', 'receive (0.946)', 'membership (0.938)', 'bank (0.938)', 'message (0.937)', 'review (0.935)', 'email (0.932)', 'verify (0.931)', 'reply (0.93)', 'blocked (0.927)']\n",
      "\n",
      "ISSUE → ['resolve (0.96)', 'resolved (0.939)', 'faced (0.934)', 'mail (0.931)', 'unable (0.931)', 'yet (0.929)', 'solve (0.929)', 'via (0.929)', 'either (0.927)', 'unfortunately (0.926)']\n",
      "\n",
      "EXPERIENCE → ['service (0.847)', 'behavior (0.837)', 'life (0.833)', 'application (0.833)', 'riding (0.832)', 'experienced (0.825)', 'travelling (0.816)', 'behaviour (0.809)', 'traveling (0.808)', 'n (0.808)']\n",
      "\n",
      "AGENT → ['text (0.989)', 'forgot (0.985)', 'purchase (0.985)', 'item (0.984)', 'missing (0.983)', 'locked (0.979)', 'sign (0.978)', 'asap (0.978)', 'pissed (0.977)', 'code (0.977)']\n",
      "\n",
      "CUSTOMER → ['proper (0.897)', 'support (0.881)', 'chat (0.847)', 'care (0.843)', 'team (0.832)', 'ai (0.823)', 'help (0.822)', 'talk (0.821)', 'poor (0.818)', 'complaint (0.818)']\n",
      "\n",
      "DROP → ['pickup (0.931)', 'spot (0.928)', 'location (0.928)', 'destination (0.912)', 'arriving (0.901)', 'end (0.899)', 'dropping (0.898)', 'road (0.897)', 'reached (0.889)', 'correct (0.883)']\n",
      "\n",
      "PICKUP → ['spot (0.959)', 'arriving (0.936)', 'drop (0.931)', 'come (0.928)', 'front (0.927)', 'road (0.926)', 'outside (0.926)', 'arrive (0.923)', 'dropped (0.92)', 'came (0.916)']\n",
      "\n",
      "WALLET → ['mode (0.973)', 'pending (0.967)', 'qr (0.959)', 'amazon (0.957)', 'upi (0.957)', 'paypal (0.948)', 'balance (0.948)', 'form (0.948)', 'digital (0.947)', 'changed (0.943)']\n",
      "\n",
      "ROUTE → ['traffic (0.932)', 'dropping (0.92)', 'distance (0.919)', 'arriving (0.917)', 'changes (0.913)', 'passenger (0.913)', 'road (0.908)', 'actual (0.908)', 'sometime (0.907)', 'arrival (0.907)']\n",
      "\n",
      "DESTINATION → ['reached (0.95)', 'reaching (0.935)', 'drop (0.912)', 'initial (0.906)', 'correct (0.905)', 'dropping (0.903)', 'outside (0.903)', 'dropped (0.901)', 'spot (0.901)', 'route (0.896)']\n",
      "\n",
      "DELAY → ['locate (0.977)', 'sometime (0.975)', 'frequently (0.975)', 'changing (0.973)', 'irritating (0.973)', 'atleast (0.972)', 'happening (0.971)', 'nearby (0.97)', 'outrageous (0.969)', 'finding (0.969)']\n",
      "\n",
      "WAIT → ['waiting (0.922)', 'waits (0.883)', 'cancels (0.878)', 'hour (0.874)', 'minute (0.873)', 'mins (0.872)', 'away (0.87)', 'ages (0.869)', '45 (0.868)', 'takes (0.865)']\n",
      "\n",
      "UBER → ['experienced (0.834)', 'bye (0.821)', 'disappointed (0.82)', 'free (0.819)', 'ui (0.818)', 'accounts (0.818)', 'onwards (0.817)', 'personally (0.817)', 'password (0.816)', 'enjoying (0.816)']\n"
     ]
    }
   ],
   "source": [
    "for seed in aspect_seeds:\n",
    "    if seed in w2v_model.wv:\n",
    "        similar = w2v_model.wv.most_similar(seed, topn=10)\n",
    "        print(f\"\\n{seed.upper()} → {[f'{word} ({round(score, 3)})' for word, score in similar]}\")\n",
    "    else:\n",
    "        print(f\"{seed} not in vocab.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "canonical_aspects = [\n",
    "    \"driver\", \"ride\", \"app\", \"fare\", \"support\", \"payment\",\n",
    "    \"booking\",  \"car\", \"interface\", \"service\",\n",
    "    \"map\", \"location\", \"tracking\", \"navigation\", \"speed\",\n",
    "     \"refund\", \"issue\", \"experience\",\n",
    "    \"agent\", \"customer\", \"drop\", \"pickup\", \"wallet\", \"route\",\n",
    "    \"destination\", \"delay\", \"wait\",\"uber\"\n",
    "]\n",
    "\n",
    "\n",
    "similarity_threshold = 0.75\n",
    "\n",
    "aspect_mapping = defaultdict(lambda: None)\n",
    "\n",
    "for canon in canonical_aspects:\n",
    "    aspect_mapping[canon] = canon  \n",
    "    similar_words =w2v_model.wv.most_similar(canon, topn=10)\n",
    "    for word, score in similar_words:\n",
    "        if score > similarity_threshold:\n",
    "            aspect_mapping[word] = canon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "driver → driver\n",
      "car → car\n",
      "man → car\n",
      "trip → ride\n",
      "he → driver\n",
      "drive → driver\n",
      "luggage → car\n",
      "ride → ride\n",
      "came → pickup\n",
      "person → car\n",
      "pickup → pickup\n",
      "coming → ride\n",
      "night → ride\n",
      "bike → ride\n",
      "once → ride\n",
      "arrival → route\n",
      "completing → ride\n",
      "confirmation → ride\n",
      "accepted → ride\n",
      "confirm → ride\n",
      "app → app\n",
      "application → experience\n",
      "fare → booking\n",
      "shown → booking\n",
      "reaching → destination\n",
      "booking → booking\n",
      "increased → booking\n",
      "fair → booking\n",
      "shows → booking\n",
      "double → fare\n",
      "showing → fare\n",
      "increase → booking\n",
      "different → fare\n",
      "support → customer\n",
      "chat → customer\n",
      "team → customer\n",
      "contact → support\n",
      "proper → customer\n",
      "help → customer\n",
      "care → customer\n",
      "customer → customer\n",
      "number → support\n",
      "ai → customer\n",
      "mail → issue\n",
      "payment → payment\n",
      "upi → wallet\n",
      "method → payment\n",
      "cash → payment\n",
      "online → payment\n",
      "mode → wallet\n",
      "wallet → wallet\n",
      "add → payment\n",
      "pending → wallet\n",
      "digital → wallet\n",
      "fraud → payment\n",
      "while → booking\n",
      "changes → route\n",
      "initially → booking\n",
      "drove → car\n",
      "safely → car\n",
      "conversation → car\n",
      "helped → car\n",
      "guy → car\n",
      "gentleman → car\n",
      "music → car\n",
      "interface → interface\n",
      "seamless → interface\n",
      "dependable → interface\n",
      "smart → service\n",
      "timing → interface\n",
      "verry → interface\n",
      "perfect → interface\n",
      "skills → interface\n",
      "travel → service\n",
      "provider → interface\n",
      "n → experience\n",
      "service → experience\n",
      "experience → experience\n",
      "extremely → service\n",
      "behavior → experience\n",
      "navigation → navigation\n",
      "services → service\n",
      "value → service\n",
      "such → service\n",
      "map → location\n",
      "exact → map\n",
      "follow → map\n",
      "mobile → map\n",
      "properly → map\n",
      "puts → map\n",
      "picking → map\n",
      "locations → map\n",
      "mine → map\n",
      "completely → map\n",
      "directions → map\n",
      "location → drop\n",
      "drop → destination\n",
      "spot → destination\n",
      "wrong → location\n",
      "correct → destination\n",
      "come → pickup\n",
      "destination → destination\n",
      "place → location\n",
      "end → drop\n",
      "tracking → tracking\n",
      "anybody → tracking\n",
      "incredibly → tracking\n",
      "persons → tracking\n",
      "shift → tracking\n",
      "list → tracking\n",
      "truly → tracking\n",
      "facility → tracking\n",
      "join → tracking\n",
      "dissatisfied → tracking\n",
      "cheapest → navigation\n",
      "platform → navigation\n",
      "providing → navigation\n",
      "l → navigation\n",
      "anytime → navigation\n",
      "transport → navigation\n",
      "meet → navigation\n",
      "simple → navigation\n",
      "smell → navigation\n",
      "careful → navigation\n",
      "speed → speed\n",
      "receives → speed\n",
      "america → speed\n",
      "silly → speed\n",
      "controls → speed\n",
      "potential → speed\n",
      "toyota → speed\n",
      "hotel → speed\n",
      "xx → speed\n",
      "delays → speed\n",
      "bristol → speed\n",
      "refund → refund\n",
      "credit → refund\n",
      "receive → refund\n",
      "membership → refund\n",
      "bank → refund\n",
      "message → refund\n",
      "review → refund\n",
      "email → refund\n",
      "verify → refund\n",
      "reply → refund\n",
      "blocked → refund\n",
      "issue → issue\n",
      "resolve → issue\n",
      "resolved → issue\n",
      "faced → issue\n",
      "unable → issue\n",
      "yet → issue\n",
      "solve → issue\n",
      "via → issue\n",
      "either → issue\n",
      "unfortunately → issue\n",
      "life → experience\n",
      "riding → experience\n",
      "experienced → uber\n",
      "travelling → experience\n",
      "behaviour → experience\n",
      "traveling → experience\n",
      "agent → agent\n",
      "text → agent\n",
      "forgot → agent\n",
      "purchase → agent\n",
      "item → agent\n",
      "missing → agent\n",
      "locked → agent\n",
      "sign → agent\n",
      "asap → agent\n",
      "pissed → agent\n",
      "code → agent\n",
      "talk → customer\n",
      "poor → customer\n",
      "complaint → customer\n",
      "arriving → route\n",
      "dropping → destination\n",
      "road → route\n",
      "reached → destination\n",
      "front → pickup\n",
      "outside → destination\n",
      "arrive → pickup\n",
      "dropped → destination\n",
      "qr → wallet\n",
      "amazon → wallet\n",
      "paypal → wallet\n",
      "balance → wallet\n",
      "form → wallet\n",
      "changed → wallet\n",
      "route → destination\n",
      "traffic → route\n",
      "distance → route\n",
      "passenger → route\n",
      "actual → route\n",
      "sometime → delay\n",
      "initial → destination\n",
      "delay → delay\n",
      "locate → delay\n",
      "frequently → delay\n",
      "changing → delay\n",
      "irritating → delay\n",
      "atleast → delay\n",
      "happening → delay\n",
      "nearby → delay\n",
      "outrageous → delay\n",
      "finding → delay\n",
      "wait → wait\n",
      "waiting → wait\n",
      "waits → wait\n",
      "cancels → wait\n",
      "hour → wait\n",
      "minute → wait\n",
      "mins → wait\n",
      "away → wait\n",
      "ages → wait\n",
      "45 → wait\n",
      "takes → wait\n",
      "uber → uber\n",
      "bye → uber\n",
      "disappointed → uber\n",
      "free → uber\n",
      "ui → uber\n",
      "accounts → uber\n",
      "onwards → uber\n",
      "personally → uber\n",
      "password → uber\n",
      "enjoying → uber\n"
     ]
    }
   ],
   "source": [
    "for word, mapped_to in aspect_mapping.items():\n",
    "    print(f\"{word} → {mapped_to}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mapping_df = pd.DataFrame(list(aspect_mapping.items()), columns=[\"Original_Word\", \"Mapped_Aspect\"])\n",
    "mapping_df.to_csv(\"aspect_mappings.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MANUALLY EDITING THE ASPECT MAPPINGS ON TOP OF COSINE SIM. FOR PRECISED MAPPINGS AND BETTER EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually edited file\n",
    "refined_df = pd.read_csv(\"updated_aspect_mappings.csv\")\n",
    "\n",
    "\n",
    "aspect_mapping = dict(zip(refined_df[\"Original_Word\"], refined_df[\"Mapped_Aspect\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRECISED NORMALISATION (ASPECT MAPPING) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "driver → driver\n",
      "car → car\n",
      "trip → ride\n",
      "ride → ride\n",
      "journey → car\n",
      "she → car\n",
      "vehicle → car\n",
      "drive → driver\n",
      "drove → driver\n",
      "arrived → wait\n",
      "rider → driver\n",
      "bike → car\n",
      "request → ride\n",
      "destination → destination\n",
      "confirmation → ride\n",
      "increased → fare\n",
      "rides → ride\n",
      "app → app\n",
      "application → app\n",
      "company → app\n",
      "experience → experience\n",
      "aap → app\n",
      "platform → uber\n",
      "seen → -\n",
      "ever → app\n",
      "services → service\n",
      "life → experience\n",
      "travel → service\n",
      "fare → fare\n",
      "booking → booking\n",
      "shown → fare\n",
      "increase → fare\n",
      "showing → fare\n",
      "shows → fare\n",
      "while → ride\n",
      "reaching → destination\n",
      "double → booking\n",
      "fair → fare\n",
      "changes → route\n",
      "support → support\n",
      "number → customer\n",
      "contact → support\n",
      "proper → support\n",
      "care → support\n",
      "team → support\n",
      "help → support\n",
      "chat → support\n",
      "customer → customer\n",
      "issues → support\n",
      "provide → service\n",
      "payment → payment\n",
      "cash → payment\n",
      "upi → payment\n",
      "method → payment\n",
      "online → payment\n",
      "amount → payment\n",
      "pending → payment\n",
      "which → -\n",
      "mode → payment\n",
      "wallet → payment\n",
      "add → payment\n",
      "price → fare\n",
      "cab → car\n",
      "auto → car\n",
      "booked → booking\n",
      "initially → car\n",
      "day → -\n",
      "book → booking\n",
      "safely → ride\n",
      "person → driver\n",
      "gentleman → driver\n",
      "conversation → driver\n",
      "our → experience\n",
      "top → -\n",
      "provided → experience\n",
      "respectful → driver\n",
      "calm → driver\n",
      "vehicles → car\n",
      "helped → driver\n",
      "interface → interface\n",
      "perfect → uber\n",
      "verry → uber\n",
      "timing → ride\n",
      "dependable → interface\n",
      "seamless → navigation\n",
      "recommended → interface\n",
      "smart → interface\n",
      "n → -\n",
      "fantastic → interface\n",
      "budget → service\n",
      "service → service\n",
      "behavior → driver\n",
      "behaviour → driver\n",
      "extremely → driver\n",
      "safety → experience\n",
      "guy → experience\n",
      "map → map\n",
      "locations → map\n",
      "screen → interface\n",
      "turn → map\n",
      "down → map\n",
      "right → map\n",
      "failed → map\n",
      "follow → map\n",
      "exact → destination\n",
      "easily → map\n",
      "correct → destination\n",
      "location → drop\n",
      "drop → drop\n",
      "point → location\n",
      "spot → pickup\n",
      "off → drop\n",
      "wrong → location\n",
      "pickup → destination\n",
      "picked → destination\n",
      "tracking → tracking\n",
      "l → -\n",
      "cheapest → service\n",
      "loved → service\n",
      "hassle → service\n",
      "wow → service\n",
      "irritating → experience\n",
      "inconsistent → interface\n",
      "generally → tracking\n",
      "ui → interface\n",
      "dissatisfied → experience\n",
      "navigation → navigation\n",
      "loving → navigation\n",
      "superb → navigation\n",
      "providing → navigation\n",
      "slow → navigation\n",
      "management → support\n",
      "offers → support\n",
      "god → navigation\n",
      "speed → speed\n",
      "light → speed\n",
      "illegally → experience\n",
      "btw → -\n",
      "sadly → -\n",
      "silly → -\n",
      "mornings → -\n",
      "discounted → fare\n",
      "locking → speed\n",
      "progressively → speed\n",
      "artists → -\n",
      "low → fare\n",
      "reasonable → fare\n",
      "high → fare\n",
      "cost → fare\n",
      "prices → fare\n",
      "initial → fare\n",
      "distance → route\n",
      "bit → fare\n",
      "passenger → customer\n",
      "costing → fare\n",
      "actual → fare\n",
      "bill → fare\n",
      "selected → fare\n",
      "argue → driver\n",
      "original → fare\n",
      "1000 → fare\n",
      "200 → fare\n",
      "increasing → fare\n",
      "completion → ride\n",
      "14 → -\n",
      "returning → fare\n",
      "payed → fare\n",
      "refund → refund\n",
      "credit → refund\n",
      "receive → refund\n",
      "message → refund\n",
      "verify → refund\n",
      "reply → refund\n",
      "answer → refund\n",
      "back → refund\n",
      "respond → refund\n",
      "email → refund\n",
      "issue → support\n",
      "problem → support\n",
      "resolve → support\n",
      "faced → support\n",
      "unable → support\n",
      "resolved → support\n",
      "tried → issue\n",
      "yet → issue\n",
      "membership → support\n",
      "solve → support\n",
      "complaint → support\n",
      "riding → experience\n",
      "enjoyed → experience\n",
      "satisfied → experience\n",
      "experienced → experience\n",
      "agent → agent\n",
      "notice → agent\n",
      "specific → agent\n",
      "text → agent\n",
      "happen → agent\n",
      "transaction → payment\n",
      "missing → agent\n",
      "ignore → agent\n",
      "explain → agent\n",
      "asap → agent\n",
      "verified → wallet\n",
      "horrible → driver\n",
      "dropped → destination\n",
      "reached → destination\n",
      "went → pickup\n",
      "morning → pickup\n",
      "arrive → route\n",
      "came → pickup\n",
      "road → pickup\n",
      "deleted → wallet\n",
      "complained → customer\n",
      "id → customer\n",
      "unfortunately → experience\n",
      "urgently → -\n",
      "wanted → -\n",
      "route → route\n",
      "nearby → route\n",
      "ends → destination\n",
      "goes → route\n",
      "suddenly → route\n",
      "accepting → route\n",
      "coming → route\n",
      "changing → route\n",
      "side → destination\n",
      "different → destination\n",
      "asked → destination\n",
      "delay → delay\n",
      "locate → delay\n",
      "sometime → delay\n",
      "small → delay\n",
      "quicker → delay\n",
      "story → delay\n",
      "outrageous → delay\n",
      "convenience → delay\n",
      "happening → delay\n",
      "busy → delay\n",
      "wait → wait\n",
      "waiting → wait\n",
      "45 → wait\n",
      "minute → wait\n",
      "plus → wait\n",
      "mins → wait\n",
      "minutes → wait\n",
      "half → wait\n",
      "hours → wait\n",
      "within → wait\n",
      "miles → wait\n",
      "uber → uber\n",
      "business → uber\n",
      "shuttle → uber\n",
      "bolt → uber\n",
      "everyone → uber\n",
      "kindly → uber\n",
      "definitely → uber\n",
      "deleting → uber\n",
      "daily → uber\n",
      "big → uber\n",
      "drivers → driver\n"
     ]
    }
   ],
   "source": [
    "for word, mapped_to in aspect_mapping.items():\n",
    "    print(f\"{word} → {mapped_to}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_df.to_csv(\"refined_expanded_aspect_seeds.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_df = pd.read_csv(\"bert_extracted_with_sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                uber\n",
       "1                uber\n",
       "2                uber\n",
       "3                uber\n",
       "4                uber\n",
       "             ...     \n",
       "19054      experience\n",
       "19055            app,\n",
       "19056         problem\n",
       "19057    application.\n",
       "19058        location\n",
       "Name: predicted_aspects, Length: 19059, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_df[\"predicted_aspects\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_df[\"Normalized_Aspect\"] = bert_df[\"predicted_aspects\"].apply(lambda x: aspect_mapping.get(x, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                uber\n",
       "1                uber\n",
       "2                uber\n",
       "3                uber\n",
       "4                uber\n",
       "             ...     \n",
       "19054      experience\n",
       "19055            app,\n",
       "19056         support\n",
       "19057    application.\n",
       "19058            drop\n",
       "Name: Normalized_Aspect, Length: 19059, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_df[\"Normalized_Aspect\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_df.to_csv(\"bert_extracted_with_sentiment2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABSA - ASPECT BASED SENTIMENT ANALYSIS\n",
    "\n",
    "1- WHAT,HOW AND WHY -TRIPLET EXTRACTION\n",
    "\n",
    "2- ASPECT EXTRACTION USING BERT AND SENTIMENT ANALYSIS USING ROBERT\n",
    "\n",
    "3- CONTRASTIVE ATTENTION METHOD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- WHAT,HOW AND WHY -TRIPLET EXTRACTION\n",
    "\n",
    "(What, How, Why)\n",
    " = (Aspect, Opinion, Explanation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Initialize sentiment analyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df['content'].dropna().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aspect Term Extraction (Nouns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_review(text):\n",
    "    return nlp(text.lower())\n",
    "\n",
    "\n",
    "def extract_aspect_terms(doc):\n",
    "    return [token.text for token in doc if token.pos_ == \"NOUN\" and not token.is_stop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opinion Term Extraction (Adj/Verb modifiers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_opinion_terms(doc):\n",
    "    opinions = []\n",
    "    for token in doc:\n",
    "        if token.pos_ in [\"ADJ\", \"VERB\"] and token.dep_ in [\"amod\", \"acomp\", \"xcomp\"]:\n",
    "            opinions.append(token.text)\n",
    "    return opinions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_sentiment(opinion):\n",
    "    score = analyzer.polarity_scores(opinion)[\"compound\"]\n",
    "    if score > 0.05:\n",
    "        return \"positive\"\n",
    "    elif score < -0.05:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRIPLET FORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_triplets(doc):\n",
    "    aspects = extract_aspect_terms(doc)\n",
    "    opinions = extract_opinion_terms(doc)\n",
    "    triplets = []\n",
    "    for asp in aspects:\n",
    "        for op in opinions:\n",
    "            if abs(doc.text.find(asp) - doc.text.find(op)) < 15:\n",
    "                sentiment = get_sentiment(op)\n",
    "                triplets.append((asp, sentiment, op))\n",
    "    return triplets\n",
    "\n",
    "all_triplets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for review in reviews:\n",
    "    doc = preprocess_review(review)\n",
    "    triplets = build_triplets(doc)\n",
    "    all_triplets.extend([(review, *t) for t in triplets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_df = pd.DataFrame(all_triplets, columns=[\"Review\", \"Aspect\", \"Sentiment\", \"Opinion\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect-Sentiment-Opinion triplets extracted and saved.\n"
     ]
    }
   ],
   "source": [
    "triplet_df.to_csv(\"uber_sentiment_triplets.csv\", index=False)\n",
    "print(\"Aspect-Sentiment-Opinion triplets extracted and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Opinion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Michelle was a very friendly and personable pe...</td>\n",
       "      <td>person</td>\n",
       "      <td>positive</td>\n",
       "      <td>friendly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bast price pr car available</td>\n",
       "      <td>price</td>\n",
       "      <td>neutral</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bast price pr car available</td>\n",
       "      <td>pr</td>\n",
       "      <td>neutral</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bast price pr car available</td>\n",
       "      <td>car</td>\n",
       "      <td>neutral</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good service</td>\n",
       "      <td>service</td>\n",
       "      <td>positive</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13888</th>\n",
       "      <td>Very bad experience with this app, booked a sh...</td>\n",
       "      <td>experience</td>\n",
       "      <td>negative</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13889</th>\n",
       "      <td>Very bad experience with this app, booked a sh...</td>\n",
       "      <td>app</td>\n",
       "      <td>neutral</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13890</th>\n",
       "      <td>Very bad experience with this app, booked a sh...</td>\n",
       "      <td>ride</td>\n",
       "      <td>neutral</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13891</th>\n",
       "      <td>Very bad experience with this app, booked a sh...</td>\n",
       "      <td>ride</td>\n",
       "      <td>neutral</td>\n",
       "      <td>50rs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13892</th>\n",
       "      <td>Very bad experience with this app, booked a sh...</td>\n",
       "      <td>application</td>\n",
       "      <td>negative</td>\n",
       "      <td>worst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13893 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review       Aspect  \\\n",
       "0      Michelle was a very friendly and personable pe...       person   \n",
       "1                            Bast price pr car available        price   \n",
       "2                            Bast price pr car available           pr   \n",
       "3                            Bast price pr car available          car   \n",
       "4                                           Good service      service   \n",
       "...                                                  ...          ...   \n",
       "13888  Very bad experience with this app, booked a sh...   experience   \n",
       "13889  Very bad experience with this app, booked a sh...          app   \n",
       "13890  Very bad experience with this app, booked a sh...         ride   \n",
       "13891  Very bad experience with this app, booked a sh...         ride   \n",
       "13892  Very bad experience with this app, booked a sh...  application   \n",
       "\n",
       "      Sentiment    Opinion  \n",
       "0      positive   friendly  \n",
       "1       neutral  available  \n",
       "2       neutral  available  \n",
       "3       neutral  available  \n",
       "4      positive       good  \n",
       "...         ...        ...  \n",
       "13888  negative        bad  \n",
       "13889   neutral      short  \n",
       "13890   neutral      short  \n",
       "13891   neutral       50rs  \n",
       "13892  negative      worst  \n",
       "\n",
       "[13893 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplet_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize aspects using the mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Aspect'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\aayan\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Aspect'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Normalize aspects using the mapping\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m triplet_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNormalized_Aspect\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m triplet_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAspect\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: aspect_mapping\u001b[38;5;241m.\u001b[39mget(x, x))\n",
      "File \u001b[1;32mc:\\Users\\aayan\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\aayan\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Aspect'"
     ]
    }
   ],
   "source": [
    "triplet_df[\"Normalized_Aspect\"] = triplet_df[\"Aspect\"].apply(lambda x: aspect_mapping.get(x, x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For evaluation and downstream processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_df[\"Aspect\"] = triplet_df[\"Normalized_Aspect\"]\n",
    "triplet_df.drop(columns=[\"Normalized_Aspect\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_df.columns = triplet_df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>aspect</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>opinion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Michelle was a very friendly and personable pe...</td>\n",
       "      <td>driver</td>\n",
       "      <td>positive</td>\n",
       "      <td>friendly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bast price pr car available</td>\n",
       "      <td>fare</td>\n",
       "      <td>neutral</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bast price pr car available</td>\n",
       "      <td>pr</td>\n",
       "      <td>neutral</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bast price pr car available</td>\n",
       "      <td>car</td>\n",
       "      <td>neutral</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good service</td>\n",
       "      <td>service</td>\n",
       "      <td>positive</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13888</th>\n",
       "      <td>Very bad experience with this app, booked a sh...</td>\n",
       "      <td>experience</td>\n",
       "      <td>negative</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13889</th>\n",
       "      <td>Very bad experience with this app, booked a sh...</td>\n",
       "      <td>app</td>\n",
       "      <td>neutral</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13890</th>\n",
       "      <td>Very bad experience with this app, booked a sh...</td>\n",
       "      <td>ride</td>\n",
       "      <td>neutral</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13891</th>\n",
       "      <td>Very bad experience with this app, booked a sh...</td>\n",
       "      <td>ride</td>\n",
       "      <td>neutral</td>\n",
       "      <td>50rs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13892</th>\n",
       "      <td>Very bad experience with this app, booked a sh...</td>\n",
       "      <td>app</td>\n",
       "      <td>negative</td>\n",
       "      <td>worst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13893 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review      aspect  \\\n",
       "0      Michelle was a very friendly and personable pe...      driver   \n",
       "1                            Bast price pr car available        fare   \n",
       "2                            Bast price pr car available          pr   \n",
       "3                            Bast price pr car available         car   \n",
       "4                                           Good service     service   \n",
       "...                                                  ...         ...   \n",
       "13888  Very bad experience with this app, booked a sh...  experience   \n",
       "13889  Very bad experience with this app, booked a sh...         app   \n",
       "13890  Very bad experience with this app, booked a sh...        ride   \n",
       "13891  Very bad experience with this app, booked a sh...        ride   \n",
       "13892  Very bad experience with this app, booked a sh...         app   \n",
       "\n",
       "      sentiment    opinion  \n",
       "0      positive   friendly  \n",
       "1       neutral  available  \n",
       "2       neutral  available  \n",
       "3       neutral  available  \n",
       "4      positive       good  \n",
       "...         ...        ...  \n",
       "13888  negative        bad  \n",
       "13889   neutral      short  \n",
       "13890   neutral      short  \n",
       "13891   neutral       50rs  \n",
       "13892  negative      worst  \n",
       "\n",
       "[13893 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_df.to_csv(\"triplet_extraction_vader\",index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOADING THE MANUALLY ASPECT EXTRACTED DATASET FOR EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df = pd.read_csv(\"Gold_Standard__Only_B-ASP_Considered_.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>aspect</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>opinion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Efficient, driver is professional, cost is rea...</td>\n",
       "      <td>driver</td>\n",
       "      <td>positive</td>\n",
       "      <td>friendly/nice/polite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Efficient, driver is professional, cost is rea...</td>\n",
       "      <td>fare</td>\n",
       "      <td>positive</td>\n",
       "      <td>cheap/reasonable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Waiting charge is extra bad experience</td>\n",
       "      <td>wait</td>\n",
       "      <td>negative</td>\n",
       "      <td>waiting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good service</td>\n",
       "      <td>service</td>\n",
       "      <td>positive</td>\n",
       "      <td>good/great/nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Worst customer service On 19/11/24 I booked an...</td>\n",
       "      <td>driver</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Don't install this uber app.. totally waste of...</td>\n",
       "      <td>driver</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Don't install this uber app.. totally waste of...</td>\n",
       "      <td>app</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Don't install this uber app.. totally waste of...</td>\n",
       "      <td>service</td>\n",
       "      <td>negative</td>\n",
       "      <td>bad/poor/worst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>make app user friendly.one can understand easily</td>\n",
       "      <td>app</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>On time u reached the location Fast service</td>\n",
       "      <td>service</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review   aspect sentiment  \\\n",
       "0    Efficient, driver is professional, cost is rea...   driver  positive   \n",
       "1    Efficient, driver is professional, cost is rea...     fare  positive   \n",
       "2               Waiting charge is extra bad experience     wait  negative   \n",
       "3                                         Good service  service  positive   \n",
       "4    Worst customer service On 19/11/24 I booked an...   driver   neutral   \n",
       "..                                                 ...      ...       ...   \n",
       "104  Don't install this uber app.. totally waste of...   driver   neutral   \n",
       "105  Don't install this uber app.. totally waste of...      app   neutral   \n",
       "106  Don't install this uber app.. totally waste of...  service  negative   \n",
       "107   make app user friendly.one can understand easily      app   neutral   \n",
       "108        On time u reached the location Fast service  service   neutral   \n",
       "\n",
       "                  opinion  \n",
       "0    friendly/nice/polite  \n",
       "1        cheap/reasonable  \n",
       "2                 waiting  \n",
       "3         good/great/nice  \n",
       "4                     NaN  \n",
       "..                    ...  \n",
       "104                   NaN  \n",
       "105                   NaN  \n",
       "106        bad/poor/worst  \n",
       "107                   NaN  \n",
       "108                   NaN  \n",
       "\n",
       "[109 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluating aspect extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df[\"aspect\"] = gold_df[\"aspect\"].apply(lambda x: aspect_mapping.get(x, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>aspect</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>opinion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Efficient, driver is professional, cost is rea...</td>\n",
       "      <td>driver</td>\n",
       "      <td>positive</td>\n",
       "      <td>friendly/nice/polite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Efficient, driver is professional, cost is rea...</td>\n",
       "      <td>fare</td>\n",
       "      <td>positive</td>\n",
       "      <td>cheap/reasonable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Waiting charge is extra bad experience</td>\n",
       "      <td>wait</td>\n",
       "      <td>negative</td>\n",
       "      <td>waiting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good service</td>\n",
       "      <td>service</td>\n",
       "      <td>positive</td>\n",
       "      <td>good/great/nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Worst customer service On 19/11/24 I booked an...</td>\n",
       "      <td>driver</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Don't install this uber app.. totally waste of...</td>\n",
       "      <td>driver</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Don't install this uber app.. totally waste of...</td>\n",
       "      <td>app</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Don't install this uber app.. totally waste of...</td>\n",
       "      <td>service</td>\n",
       "      <td>negative</td>\n",
       "      <td>bad/poor/worst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>make app user friendly.one can understand easily</td>\n",
       "      <td>app</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>On time u reached the location Fast service</td>\n",
       "      <td>service</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review   aspect sentiment  \\\n",
       "0    Efficient, driver is professional, cost is rea...   driver  positive   \n",
       "1    Efficient, driver is professional, cost is rea...     fare  positive   \n",
       "2               Waiting charge is extra bad experience     wait  negative   \n",
       "3                                         Good service  service  positive   \n",
       "4    Worst customer service On 19/11/24 I booked an...   driver   neutral   \n",
       "..                                                 ...      ...       ...   \n",
       "104  Don't install this uber app.. totally waste of...   driver   neutral   \n",
       "105  Don't install this uber app.. totally waste of...      app   neutral   \n",
       "106  Don't install this uber app.. totally waste of...  service  negative   \n",
       "107   make app user friendly.one can understand easily      app   neutral   \n",
       "108        On time u reached the location Fast service  service   neutral   \n",
       "\n",
       "                  opinion  \n",
       "0    friendly/nice/polite  \n",
       "1        cheap/reasonable  \n",
       "2                 waiting  \n",
       "3         good/great/nice  \n",
       "4                     NaN  \n",
       "..                    ...  \n",
       "104                   NaN  \n",
       "105                   NaN  \n",
       "106        bad/poor/worst  \n",
       "107                   NaN  \n",
       "108                   NaN  \n",
       "\n",
       "[109 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Group aspects by review\n",
    "def group_aspects_by_review(df):\n",
    "    grouped = defaultdict(set)\n",
    "    for _, row in df.iterrows():\n",
    "        grouped[row[\"review\"]].add(row[\"aspect\"].lower())  # normalize case\n",
    "    return grouped\n",
    "\n",
    "# Gold and predicted groupings\n",
    "gold_aspects = group_aspects_by_review(gold_df)\n",
    "pred_aspects = group_aspects_by_review(triplet_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positives = 0\n",
    "false_positives = 0\n",
    "false_negatives = 0\n",
    "\n",
    "for review in gold_aspects:\n",
    "    gold_set = gold_aspects[review]\n",
    "    pred_set = pred_aspects.get(review, set())\n",
    "\n",
    "    true_positives += len(gold_set & pred_set)\n",
    "    false_positives += len(pred_set - gold_set)\n",
    "    false_negatives += len(gold_set - pred_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATION OF POS-TAGGER FOR ASPECT EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect Extraction Evaluation:\n",
      "Precision: 0.366, Recall: 0.486, F1: 0.417\n"
     ]
    }
   ],
   "source": [
    "precision = true_positives / (true_positives + false_positives + 1e-10)\n",
    "recall = true_positives / (true_positives + false_negatives + 1e-10)\n",
    "f1 = 2 * precision * recall / (precision + recall + 1e-10)\n",
    "\n",
    "print(f\"Aspect Extraction Evaluation:\\nPrecision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Precision: 0.366, Recall: 0.486, F1: 0.417"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_cases = []\n",
    "\n",
    "for review in gold_aspects:\n",
    "    gold_set = gold_aspects[review]\n",
    "    pred_set = pred_aspects.get(review, set())\n",
    "\n",
    "    false_positives = pred_set - gold_set\n",
    "    false_negatives = gold_set - pred_set\n",
    "\n",
    "    if false_positives or false_negatives:\n",
    "        error_cases.append({\n",
    "            \"review\": review,\n",
    "            \"gold_aspects\": list(gold_set),\n",
    "            \"predicted_aspects\": list(pred_set),\n",
    "            \"false_positives\": list(false_positives),\n",
    "            \"false_negatives\": list(false_negatives)\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>gold_aspects</th>\n",
       "      <th>predicted_aspects</th>\n",
       "      <th>false_positives</th>\n",
       "      <th>false_negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Waiting charge is extra bad experience</td>\n",
       "      <td>[wait]</td>\n",
       "      <td>[experience, charge]</td>\n",
       "      <td>[experience, charge]</td>\n",
       "      <td>[wait]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Worst customer service On 19/11/24 I booked an...</td>\n",
       "      <td>[driver, service, app]</td>\n",
       "      <td>[ride, customer, cancellation, fee, app]</td>\n",
       "      <td>[ride, customer, fee, cancellation]</td>\n",
       "      <td>[driver, service]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reliable and timescale and easy tovl use with ...</td>\n",
       "      <td>[fare]</td>\n",
       "      <td>[fare, tovl]</td>\n",
       "      <td>[tovl]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Always a pleasure to ride with Uber drivers. Q...</td>\n",
       "      <td>[driver]</td>\n",
       "      <td>[driver, ups, pick]</td>\n",
       "      <td>[ups, pick]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good service...</td>\n",
       "      <td>[service]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[service]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Quick service on a busy Friday evening.</td>\n",
       "      <td>[service]</td>\n",
       "      <td>[service, evening]</td>\n",
       "      <td>[evening]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>It is a cheating app. While booking the ride i...</td>\n",
       "      <td>[driver, fare, app]</td>\n",
       "      <td>[app]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[driver, fare]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I love that app</td>\n",
       "      <td>[app]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[app]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Even single star is waste... Driver will not l...</td>\n",
       "      <td>[driver]</td>\n",
       "      <td>[time, 10min, fee, star]</td>\n",
       "      <td>[time, 10min, fee, star]</td>\n",
       "      <td>[driver]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1st time using the app, enjoyed the discussion...</td>\n",
       "      <td>[driver, service, app]</td>\n",
       "      <td>[time, uber, service, workings]</td>\n",
       "      <td>[time, uber, workings]</td>\n",
       "      <td>[driver, app]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review            gold_aspects  \\\n",
       "0             Waiting charge is extra bad experience                  [wait]   \n",
       "1  Worst customer service On 19/11/24 I booked an...  [driver, service, app]   \n",
       "2  Reliable and timescale and easy tovl use with ...                  [fare]   \n",
       "3  Always a pleasure to ride with Uber drivers. Q...                [driver]   \n",
       "4                                    Good service...               [service]   \n",
       "5            Quick service on a busy Friday evening.               [service]   \n",
       "6  It is a cheating app. While booking the ride i...     [driver, fare, app]   \n",
       "7                                    I love that app                   [app]   \n",
       "8  Even single star is waste... Driver will not l...                [driver]   \n",
       "9  1st time using the app, enjoyed the discussion...  [driver, service, app]   \n",
       "\n",
       "                          predicted_aspects  \\\n",
       "0                      [experience, charge]   \n",
       "1  [ride, customer, cancellation, fee, app]   \n",
       "2                              [fare, tovl]   \n",
       "3                       [driver, ups, pick]   \n",
       "4                                        []   \n",
       "5                        [service, evening]   \n",
       "6                                     [app]   \n",
       "7                                        []   \n",
       "8                  [time, 10min, fee, star]   \n",
       "9           [time, uber, service, workings]   \n",
       "\n",
       "                       false_positives    false_negatives  \n",
       "0                 [experience, charge]             [wait]  \n",
       "1  [ride, customer, fee, cancellation]  [driver, service]  \n",
       "2                               [tovl]                 []  \n",
       "3                          [ups, pick]                 []  \n",
       "4                                   []          [service]  \n",
       "5                            [evening]                 []  \n",
       "6                                   []     [driver, fare]  \n",
       "7                                   []              [app]  \n",
       "8             [time, 10min, fee, star]           [driver]  \n",
       "9               [time, uber, workings]      [driver, app]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "error_df = pd.DataFrame(error_cases)\n",
    "from IPython.display import display\n",
    "display(error_df.head(10))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2: BERT-Based Aspect Extraction + RoBERTa-Based Sentiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Phase 1: Aspect Extraction using BERT\n",
    " \n",
    "Identify which words in a review are aspects, using BIO tagging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preparing BIO labelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " BIO-labeled dataset saved.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "df2 = pd.read_csv(\"uber_reviews_without_reviewid.csv\").dropna(subset=[\"content\"])\n",
    "\n",
    "expanded = pd.read_csv(\"refined_expanded_aspect_seeds.csv\")\n",
    "aspect_vocab = set(expanded[\"similar_word\"].tolist()) | set(expanded[\"aspect_seed\"].tolist())\n",
    "\n",
    "def tokenize(text):\n",
    "    return re.findall(r\"\\w+\", str(text).lower())\n",
    "\n",
    "def bio_tag_tokens(text, aspect_list):\n",
    "    tokens = tokenize(text)\n",
    "    tags = [\"O\"] * len(tokens)\n",
    "\n",
    "    for i in range(len(tokens)):\n",
    "        for phrase in aspect_list:\n",
    "            phrase_tokens = phrase.split()\n",
    "            if tokens[i:i+len(phrase_tokens)] == phrase_tokens:\n",
    "                tags[i] = \"B-ASP\"\n",
    "                for j in range(1, len(phrase_tokens)):\n",
    "                    if i + j < len(tokens):\n",
    "                        tags[i + j] = \"I-ASP\"\n",
    "                break\n",
    "    return tokens, tags\n",
    "\n",
    "\n",
    "bio_samples = []\n",
    "for text in df[\"content\"].unique():\n",
    "    tokens, tags = bio_tag_tokens(text, aspect_vocab)\n",
    "    if \"B-ASP\" in tags:  \n",
    "        bio_samples.append((text, tokens, tags))\n",
    "\n",
    "bio_df = pd.DataFrame(bio_samples, columns=[\"sentence\", \"tokens\", \"tags\"])\n",
    "bio_df.to_csv(\"bio_labeled_aspects.csv\", index=False)\n",
    "print(\" BIO-labeled dataset saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Michelle was a very friendly and personable pe...</td>\n",
       "      <td>[michelle, was, a, very, friendly, and, person...</td>\n",
       "      <td>[O, O, O, O, O, O, O, B-ASP, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bast price pr car available</td>\n",
       "      <td>[bast, price, pr, car, available]</td>\n",
       "      <td>[O, B-ASP, O, B-ASP, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good service</td>\n",
       "      <td>[good, service]</td>\n",
       "      <td>[O, B-ASP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Never using uber again in Europe, thry charged...</td>\n",
       "      <td>[never, using, uber, again, in, europe, thry, ...</td>\n",
       "      <td>[O, O, B-ASP, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nice app</td>\n",
       "      <td>[nice, app]</td>\n",
       "      <td>[O, B-ASP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5450</th>\n",
       "      <td>Most poor service yours company and I don't li...</td>\n",
       "      <td>[most, poor, service, yours, company, and, i, ...</td>\n",
       "      <td>[O, O, B-ASP, O, O, O, O, O, O, O, O, O, O, B-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5451</th>\n",
       "      <td>This company uses unethical methods of having ...</td>\n",
       "      <td>[this, company, uses, unethical, methods, of, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>Can't book uber shuttle no matter which paymen...</td>\n",
       "      <td>[can, t, book, uber, shuttle, no, matter, whic...</td>\n",
       "      <td>[O, O, O, B-ASP, B-ASP, O, O, O, B-ASP, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5453</th>\n",
       "      <td>Worst experience after 10pm in Hyde cityno aut...</td>\n",
       "      <td>[worst, experience, after, 10pm, in, hyde, cit...</td>\n",
       "      <td>[O, B-ASP, O, O, O, O, O, B-ASP, O, O, B-ASP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5454</th>\n",
       "      <td>Very bad experience with this app, booked a sh...</td>\n",
       "      <td>[very, bad, experience, with, this, app, booke...</td>\n",
       "      <td>[O, O, B-ASP, O, O, B-ASP, O, O, O, B-ASP, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5455 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  \\\n",
       "0     Michelle was a very friendly and personable pe...   \n",
       "1                           Bast price pr car available   \n",
       "2                                          Good service   \n",
       "3     Never using uber again in Europe, thry charged...   \n",
       "4                                              Nice app   \n",
       "...                                                 ...   \n",
       "5450  Most poor service yours company and I don't li...   \n",
       "5451  This company uses unethical methods of having ...   \n",
       "5452  Can't book uber shuttle no matter which paymen...   \n",
       "5453  Worst experience after 10pm in Hyde cityno aut...   \n",
       "5454  Very bad experience with this app, booked a sh...   \n",
       "\n",
       "                                                 tokens  \\\n",
       "0     [michelle, was, a, very, friendly, and, person...   \n",
       "1                     [bast, price, pr, car, available]   \n",
       "2                                       [good, service]   \n",
       "3     [never, using, uber, again, in, europe, thry, ...   \n",
       "4                                           [nice, app]   \n",
       "...                                                 ...   \n",
       "5450  [most, poor, service, yours, company, and, i, ...   \n",
       "5451  [this, company, uses, unethical, methods, of, ...   \n",
       "5452  [can, t, book, uber, shuttle, no, matter, whic...   \n",
       "5453  [worst, experience, after, 10pm, in, hyde, cit...   \n",
       "5454  [very, bad, experience, with, this, app, booke...   \n",
       "\n",
       "                                                   tags  \n",
       "0                    [O, O, O, O, O, O, O, B-ASP, O, O]  \n",
       "1                               [O, B-ASP, O, B-ASP, O]  \n",
       "2                                            [O, B-ASP]  \n",
       "3     [O, O, B-ASP, O, O, O, O, O, O, O, O, O, O, O,...  \n",
       "4                                            [O, B-ASP]  \n",
       "...                                                 ...  \n",
       "5450  [O, O, B-ASP, O, O, O, O, O, O, O, O, O, O, B-...  \n",
       "5451  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "5452   [O, O, O, B-ASP, B-ASP, O, O, O, B-ASP, O, O, O]  \n",
       "5453      [O, B-ASP, O, O, O, O, O, B-ASP, O, O, B-ASP]  \n",
       "5454  [O, O, B-ASP, O, O, B-ASP, O, O, O, B-ASP, O, ...  \n",
       "\n",
       "[5455 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bio_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize + Align Labels + Create PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "encoded_inputs = []\n",
    "for tokens, tags in zip(bio_df[\"tokens\"], bio_df[\"tags\"]):\n",
    "    encoding = tokenizer(tokens, is_split_into_words=True, return_offsets_mapping=True, padding=\"max_length\", truncation=True, max_length=64)\n",
    "    word_ids = encoding.word_ids()\n",
    "    labels = []\n",
    "    prev_word_id = None\n",
    "    for idx in word_ids:\n",
    "        if idx is None:\n",
    "            labels.append(-100)\n",
    "        elif idx != prev_word_id:\n",
    "            labels.append(1 if tags[idx] == \"B-ASP\" else 0)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "        prev_word_id = idx\n",
    "    encoded_inputs.append({\"input_ids\": encoding[\"input_ids\"], \"attention_mask\": encoding[\"attention_mask\"], \"labels\": labels})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class AspectDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val) for key, val in self.data[idx].items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Training Code for TOKEN classification (Aspect extraction in our case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data = train_test_split(encoded_inputs, test_size=0.1, random_state=42)\n",
    "train_dataset = AspectDataset(train_data)\n",
    "val_dataset = AspectDataset(val_data)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training Loss: 10.0909\n",
      "Epoch 2 - Training Loss: 0.5095\n",
      "Epoch 3 - Training Loss: 0.4420\n",
      "Epoch 4 - Training Loss: 0.8030\n",
      "Epoch 5 - Training Loss: 0.1226\n",
      "Epoch 6 - Training Loss: 0.1910\n",
      "Epoch 7 - Training Loss: 0.1259\n",
      "Epoch 8 - Training Loss: 0.0200\n",
      "Epoch 9 - Training Loss: 0.0025\n",
      "Epoch 10 - Training Loss: 0.2585\n",
      "Epoch 11 - Training Loss: 0.3797\n",
      "Epoch 12 - Training Loss: 0.5004\n",
      "Epoch 13 - Training Loss: 0.2588\n",
      "Epoch 14 - Training Loss: 0.0445\n",
      "Epoch 15 - Training Loss: 0.0081\n",
      "Epoch 16 - Training Loss: 0.0115\n",
      "Epoch 17 - Training Loss: 0.0042\n",
      "Epoch 18 - Training Loss: 0.5444\n",
      "Epoch 19 - Training Loss: 0.2745\n",
      "Epoch 20 - Training Loss: 0.0260\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1} - Training Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bert_aspect_model\\\\tokenizer_config.json',\n",
       " 'bert_aspect_model\\\\special_tokens_map.json',\n",
       " 'bert_aspect_model\\\\vocab.txt',\n",
       " 'bert_aspect_model\\\\added_tokens.json',\n",
       " 'bert_aspect_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"bert_aspect_model\")\n",
    "tokenizer.save_pretrained(\"bert_aspect_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast, BertForTokenClassification\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained(\"bert_aspect_model\")\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert_aspect_model\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_aspects(text):\n",
    "    tokens = text.split()\n",
    "    \n",
    "    inputs = tokenizer(tokens,\n",
    "                       is_split_into_words=True,\n",
    "                       return_tensors=\"pt\",\n",
    "                       padding=True,\n",
    "                       truncation=True,\n",
    "                       max_length=64)\n",
    "\n",
    "    word_ids = inputs.word_ids(batch_index=0)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = outputs.logits.argmax(dim=-1).squeeze().tolist()\n",
    "\n",
    "    aspects = []\n",
    "    previous_word_idx = None\n",
    "    for idx, word_idx in enumerate(word_ids):\n",
    "        if word_idx is None or word_idx == previous_word_idx:\n",
    "            continue\n",
    "        if predictions[idx] == 1:  # B-ASP label\n",
    "            aspects.append(tokens[word_idx])\n",
    "        previous_word_idx = word_idx\n",
    "\n",
    "    return list(set(aspects))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_map = {}\n",
    "for key, values in aspect_mapping.items():\n",
    "    for val in values:\n",
    "        reverse_map[val] = key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_aspect(aspect):\n",
    "    aspect_lower = aspect.lower()\n",
    "    return reverse_map.get(aspect_lower, aspect_lower)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predicted_aspects = []\n",
    "for review in df[\"content\"]:\n",
    "    raw_aspects = extract_aspects(review) \n",
    "    normalized = [normalize_aspect(asp) for asp in raw_aspects]\n",
    "    all_predicted_aspects.append(list(set(normalized)))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userName</th>\n",
       "      <th>userImage</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>repliedAt</th>\n",
       "      <th>appVersion</th>\n",
       "      <th>predicted_aspects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Good</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>2024-12-18 17:17:19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>User_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nice</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>2024-12-18 17:17:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>User_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Very convenient</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.532.10001</td>\n",
       "      <td>2024-12-18 17:09:42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.532.10001</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>User_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Good</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>2024-12-18 17:08:27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>User_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>exllence</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>2024-12-18 17:08:16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>User_11995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Excellent!!!</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.553.10000</td>\n",
       "      <td>2024-11-24 21:59:16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.553.10000</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>User_11996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Worst experience after 10pm in Hyde cityno aut...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.552.10000</td>\n",
       "      <td>2024-11-24 21:56:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.552.10000</td>\n",
       "      <td>[auto, experience, ride]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>User_11997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Exceptional</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.552.10000</td>\n",
       "      <td>2024-11-24 21:52:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.552.10000</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>User_11998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Good Service.</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.553.10000</td>\n",
       "      <td>2024-11-24 21:50:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.553.10000</td>\n",
       "      <td>[service.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>User_11999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Very bad experience with this app, booked a sh...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-24 21:44:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[application., problem, experience, app,, ride...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userName  userImage  \\\n",
       "0          User_0        NaN   \n",
       "1          User_1        NaN   \n",
       "2          User_2        NaN   \n",
       "3          User_3        NaN   \n",
       "4          User_4        NaN   \n",
       "...           ...        ...   \n",
       "11995  User_11995        NaN   \n",
       "11996  User_11996        NaN   \n",
       "11997  User_11997        NaN   \n",
       "11998  User_11998        NaN   \n",
       "11999  User_11999        NaN   \n",
       "\n",
       "                                                 content  score  \\\n",
       "0                                                   Good      5   \n",
       "1                                                   Nice      5   \n",
       "2                                        Very convenient      5   \n",
       "3                                                   Good      4   \n",
       "4                                               exllence      5   \n",
       "...                                                  ...    ...   \n",
       "11995                                       Excellent!!!      5   \n",
       "11996  Worst experience after 10pm in Hyde cityno aut...      5   \n",
       "11997                                        Exceptional      5   \n",
       "11998                                      Good Service.      5   \n",
       "11999  Very bad experience with this app, booked a sh...      1   \n",
       "\n",
       "       thumbsUpCount reviewCreatedVersion                   at replyContent  \\\n",
       "0                  0          4.556.10005  2024-12-18 17:17:19          NaN   \n",
       "1                  0          4.556.10005  2024-12-18 17:17:17          NaN   \n",
       "2                  0          4.532.10001  2024-12-18 17:09:42          NaN   \n",
       "3                  0          4.556.10005  2024-12-18 17:08:27          NaN   \n",
       "4                  0          4.556.10005  2024-12-18 17:08:16          NaN   \n",
       "...              ...                  ...                  ...          ...   \n",
       "11995              0          4.553.10000  2024-11-24 21:59:16          NaN   \n",
       "11996              0          4.552.10000  2024-11-24 21:56:10          NaN   \n",
       "11997              0          4.552.10000  2024-11-24 21:52:21          NaN   \n",
       "11998              0          4.553.10000  2024-11-24 21:50:30          NaN   \n",
       "11999              0                  NaN  2024-11-24 21:44:44          NaN   \n",
       "\n",
       "      repliedAt   appVersion  \\\n",
       "0           NaN  4.556.10005   \n",
       "1           NaN  4.556.10005   \n",
       "2           NaN  4.532.10001   \n",
       "3           NaN  4.556.10005   \n",
       "4           NaN  4.556.10005   \n",
       "...         ...          ...   \n",
       "11995       NaN  4.553.10000   \n",
       "11996       NaN  4.552.10000   \n",
       "11997       NaN  4.552.10000   \n",
       "11998       NaN  4.553.10000   \n",
       "11999       NaN          NaN   \n",
       "\n",
       "                                       predicted_aspects  \n",
       "0                                                     []  \n",
       "1                                                     []  \n",
       "2                                                     []  \n",
       "3                                                     []  \n",
       "4                                                     []  \n",
       "...                                                  ...  \n",
       "11995                                                 []  \n",
       "11996                           [auto, experience, ride]  \n",
       "11997                                                 []  \n",
       "11998                                         [service.]  \n",
       "11999  [application., problem, experience, app,, ride...  \n",
       "\n",
       "[12000 rows x 11 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"predicted_aspects\"]=all_predicted_aspects\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df=pd.read_csv(\"Gold_Standard__Only_B-ASP_Considered_.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"content\": \"review\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = df[[\"review\", \"predicted_aspects\"]].merge(\n",
    "    gold_df.groupby(\"review\")[\"aspect\"].apply(list).reset_index(),\n",
    "    on=\"review\",\n",
    "    how=\"inner\"\n",
    ").rename(columns={\"aspect\": \"gold_aspects\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "true_positives, false_positives, false_negatives = 0, 0, 0\n",
    "\n",
    "for _, row in eval_df.iterrows():\n",
    "    gold = set([a.lower() for a in row[\"gold_aspects\"]])\n",
    "    pred = set([a.lower() for a in row[\"predicted_aspects\"]])\n",
    "\n",
    "    true_positives += len(gold & pred)\n",
    "    false_positives += len(pred - gold)\n",
    "    false_negatives += len(gold - pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATION OF BERT BASED ASPECT EXTRACTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision: 0.754, Recall: 0.875, F1: 0.810"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect Extraction Evaluation:\n",
      "Precision: 0.754, Recall: 0.875, F1: 0.810\n"
     ]
    }
   ],
   "source": [
    "precision = true_positives / (true_positives + false_positives + 1e-10)\n",
    "recall = true_positives / (true_positives + false_negatives + 1e-10)\n",
    "f1 = 2 * precision * recall / (precision + recall + 1e-10)\n",
    "\n",
    "print(f\"Aspect Extraction Evaluation:\\nPrecision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert =df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing empty lists with ['uber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_bert['predicted_aspects'] = df_bert['predicted_aspects'].apply(\n",
    "    lambda aspects: ['uber'] if not aspects else aspects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userName</th>\n",
       "      <th>userImage</th>\n",
       "      <th>review</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>repliedAt</th>\n",
       "      <th>appVersion</th>\n",
       "      <th>predicted_aspects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Good</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>2024-12-18 17:17:19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>[uber]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>User_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nice</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>2024-12-18 17:17:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>[uber]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>User_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Very convenient</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.532.10001</td>\n",
       "      <td>2024-12-18 17:09:42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.532.10001</td>\n",
       "      <td>[uber]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>User_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Good</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>2024-12-18 17:08:27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>[uber]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>User_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>exllence</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>2024-12-18 17:08:16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>[uber]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>User_11995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Excellent!!!</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.553.10000</td>\n",
       "      <td>2024-11-24 21:59:16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.553.10000</td>\n",
       "      <td>[uber]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>User_11996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Worst experience after 10pm in Hyde cityno aut...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.552.10000</td>\n",
       "      <td>2024-11-24 21:56:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.552.10000</td>\n",
       "      <td>[auto, experience, ride]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>User_11997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Exceptional</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.552.10000</td>\n",
       "      <td>2024-11-24 21:52:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.552.10000</td>\n",
       "      <td>[uber]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>User_11998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Good Service.</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.553.10000</td>\n",
       "      <td>2024-11-24 21:50:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.553.10000</td>\n",
       "      <td>[service.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>User_11999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Very bad experience with this app, booked a sh...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-24 21:44:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[application., problem, experience, app,, ride...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userName  userImage  \\\n",
       "0          User_0        NaN   \n",
       "1          User_1        NaN   \n",
       "2          User_2        NaN   \n",
       "3          User_3        NaN   \n",
       "4          User_4        NaN   \n",
       "...           ...        ...   \n",
       "11995  User_11995        NaN   \n",
       "11996  User_11996        NaN   \n",
       "11997  User_11997        NaN   \n",
       "11998  User_11998        NaN   \n",
       "11999  User_11999        NaN   \n",
       "\n",
       "                                                  review  score  \\\n",
       "0                                                   Good      5   \n",
       "1                                                   Nice      5   \n",
       "2                                        Very convenient      5   \n",
       "3                                                   Good      4   \n",
       "4                                               exllence      5   \n",
       "...                                                  ...    ...   \n",
       "11995                                       Excellent!!!      5   \n",
       "11996  Worst experience after 10pm in Hyde cityno aut...      5   \n",
       "11997                                        Exceptional      5   \n",
       "11998                                      Good Service.      5   \n",
       "11999  Very bad experience with this app, booked a sh...      1   \n",
       "\n",
       "       thumbsUpCount reviewCreatedVersion                   at replyContent  \\\n",
       "0                  0          4.556.10005  2024-12-18 17:17:19          NaN   \n",
       "1                  0          4.556.10005  2024-12-18 17:17:17          NaN   \n",
       "2                  0          4.532.10001  2024-12-18 17:09:42          NaN   \n",
       "3                  0          4.556.10005  2024-12-18 17:08:27          NaN   \n",
       "4                  0          4.556.10005  2024-12-18 17:08:16          NaN   \n",
       "...              ...                  ...                  ...          ...   \n",
       "11995              0          4.553.10000  2024-11-24 21:59:16          NaN   \n",
       "11996              0          4.552.10000  2024-11-24 21:56:10          NaN   \n",
       "11997              0          4.552.10000  2024-11-24 21:52:21          NaN   \n",
       "11998              0          4.553.10000  2024-11-24 21:50:30          NaN   \n",
       "11999              0                  NaN  2024-11-24 21:44:44          NaN   \n",
       "\n",
       "      repliedAt   appVersion  \\\n",
       "0           NaN  4.556.10005   \n",
       "1           NaN  4.556.10005   \n",
       "2           NaN  4.532.10001   \n",
       "3           NaN  4.556.10005   \n",
       "4           NaN  4.556.10005   \n",
       "...         ...          ...   \n",
       "11995       NaN  4.553.10000   \n",
       "11996       NaN  4.552.10000   \n",
       "11997       NaN  4.552.10000   \n",
       "11998       NaN  4.553.10000   \n",
       "11999       NaN          NaN   \n",
       "\n",
       "                                       predicted_aspects  \n",
       "0                                                 [uber]  \n",
       "1                                                 [uber]  \n",
       "2                                                 [uber]  \n",
       "3                                                 [uber]  \n",
       "4                                                 [uber]  \n",
       "...                                                  ...  \n",
       "11995                                             [uber]  \n",
       "11996                           [auto, experience, ride]  \n",
       "11997                                             [uber]  \n",
       "11998                                         [service.]  \n",
       "11999  [application., problem, experience, app,, ride...  \n",
       "\n",
       "[12000 rows x 11 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expand each aspect into a separate row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert= df_bert.explode('predicted_aspects').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userName</th>\n",
       "      <th>userImage</th>\n",
       "      <th>review</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>repliedAt</th>\n",
       "      <th>appVersion</th>\n",
       "      <th>predicted_aspects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Good</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>2024-12-18 17:17:19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>uber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>User_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nice</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>2024-12-18 17:17:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>uber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>User_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Very convenient</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.532.10001</td>\n",
       "      <td>2024-12-18 17:09:42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.532.10001</td>\n",
       "      <td>uber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>User_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Good</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>2024-12-18 17:08:27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>uber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>User_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>exllence</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>2024-12-18 17:08:16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>uber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19138</th>\n",
       "      <td>User_11999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Very bad experience with this app, booked a sh...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-24 21:44:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19139</th>\n",
       "      <td>User_11999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Very bad experience with this app, booked a sh...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-24 21:44:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19140</th>\n",
       "      <td>User_11999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Very bad experience with this app, booked a sh...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-24 21:44:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>app,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19141</th>\n",
       "      <td>User_11999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Very bad experience with this app, booked a sh...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-24 21:44:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ride</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19142</th>\n",
       "      <td>User_11999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Very bad experience with this app, booked a sh...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-24 21:44:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19143 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userName  userImage  \\\n",
       "0          User_0        NaN   \n",
       "1          User_1        NaN   \n",
       "2          User_2        NaN   \n",
       "3          User_3        NaN   \n",
       "4          User_4        NaN   \n",
       "...           ...        ...   \n",
       "19138  User_11999        NaN   \n",
       "19139  User_11999        NaN   \n",
       "19140  User_11999        NaN   \n",
       "19141  User_11999        NaN   \n",
       "19142  User_11999        NaN   \n",
       "\n",
       "                                                  review  score  \\\n",
       "0                                                   Good      5   \n",
       "1                                                   Nice      5   \n",
       "2                                        Very convenient      5   \n",
       "3                                                   Good      4   \n",
       "4                                               exllence      5   \n",
       "...                                                  ...    ...   \n",
       "19138  Very bad experience with this app, booked a sh...      1   \n",
       "19139  Very bad experience with this app, booked a sh...      1   \n",
       "19140  Very bad experience with this app, booked a sh...      1   \n",
       "19141  Very bad experience with this app, booked a sh...      1   \n",
       "19142  Very bad experience with this app, booked a sh...      1   \n",
       "\n",
       "       thumbsUpCount reviewCreatedVersion                   at replyContent  \\\n",
       "0                  0          4.556.10005  2024-12-18 17:17:19          NaN   \n",
       "1                  0          4.556.10005  2024-12-18 17:17:17          NaN   \n",
       "2                  0          4.532.10001  2024-12-18 17:09:42          NaN   \n",
       "3                  0          4.556.10005  2024-12-18 17:08:27          NaN   \n",
       "4                  0          4.556.10005  2024-12-18 17:08:16          NaN   \n",
       "...              ...                  ...                  ...          ...   \n",
       "19138              0                  NaN  2024-11-24 21:44:44          NaN   \n",
       "19139              0                  NaN  2024-11-24 21:44:44          NaN   \n",
       "19140              0                  NaN  2024-11-24 21:44:44          NaN   \n",
       "19141              0                  NaN  2024-11-24 21:44:44          NaN   \n",
       "19142              0                  NaN  2024-11-24 21:44:44          NaN   \n",
       "\n",
       "      repliedAt   appVersion predicted_aspects  \n",
       "0           NaN  4.556.10005              uber  \n",
       "1           NaN  4.556.10005              uber  \n",
       "2           NaN  4.532.10001              uber  \n",
       "3           NaN  4.556.10005              uber  \n",
       "4           NaN  4.556.10005              uber  \n",
       "...         ...          ...               ...  \n",
       "19138       NaN          NaN           problem  \n",
       "19139       NaN          NaN        experience  \n",
       "19140       NaN          NaN              app,  \n",
       "19141       NaN          NaN              ride  \n",
       "19142       NaN          NaN          location  \n",
       "\n",
       "[19143 rows x 11 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_aspects\n",
       "uber                True\n",
       "app                 True\n",
       "service             True\n",
       "driver              True\n",
       "ride                True\n",
       "                   ...  \n",
       "distance...        False\n",
       "delay.             False\n",
       "ride!!!            False\n",
       "customer.....if    False\n",
       "trip..had          False\n",
       "Name: count, Length: 638, dtype: bool"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bert[\"predicted_aspects\"].value_counts()>500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert.to_csv(\"bert_extracted_asp\",index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspects in 1: ['app']\n",
      "Aspects in 2: ['method', 'fare', 'payment']\n",
      "Aspects in 3: ['Booking', 'tracking', 'map']\n"
     ]
    }
   ],
   "source": [
    "example1 = \"The chauffeur was rude but the app worked well\"\n",
    "example2 = \"I had issues with the fare and payment method\"\n",
    "example3 = \"Booking was fast, but map tracking was off\"\n",
    "\n",
    "print(\"Aspects in 1:\", extract_aspects(example1))\n",
    "print(\"Aspects in 2:\", extract_aspects(example2))\n",
    "print(\"Aspects in 3:\", extract_aspects(example3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoBERTa Sentiment Classification for ABSA (Uber Reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (0 = negative, 1 = positive, 2 = neutral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Aspect extracted data using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv(\"bert_labeled_absa_400.csv\")\n",
    "train_df, val_df = train_test_split(df, test_size=0.1, stratify=df['label'], random_state=42)\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating custom pytroch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ABSADataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len=128):\n",
    "        self.texts = dataframe['aspect'] + \" [SEP] \" + dataframe['review']\n",
    "        self.labels = dataframe['label'].values\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.tokenizer(self.texts.iloc[idx], \n",
    "                                padding='max_length',\n",
    "                                truncation=True, \n",
    "                                max_length=self.max_len,\n",
    "                                return_tensors=\"pt\")\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ABSADataset(train_df, tokenizer)\n",
    "val_ds = ABSADataset(val_df, tokenizer)\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=3)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Training loss: 23.8331\n",
      "Validation Accuracy: 0.6500\n",
      "Epoch 2/20 - Training loss: 17.2981\n",
      "Validation Accuracy: 0.6500\n",
      "Epoch 3/20 - Training loss: 12.4656\n",
      "Validation Accuracy: 0.8750\n",
      "Epoch 4/20 - Training loss: 7.2945\n",
      "Validation Accuracy: 0.9000\n",
      "Epoch 5/20 - Training loss: 4.8314\n",
      "Validation Accuracy: 0.8250\n",
      "Epoch 6/20 - Training loss: 1.4108\n",
      "Validation Accuracy: 0.8250\n",
      "Epoch 7/20 - Training loss: 1.4935\n",
      "Validation Accuracy: 0.8750\n",
      "Epoch 8/20 - Training loss: 0.7331\n",
      "Validation Accuracy: 0.8000\n",
      "Epoch 9/20 - Training loss: 0.4764\n",
      "Validation Accuracy: 0.8750\n",
      "Epoch 10/20 - Training loss: 0.2158\n",
      "Validation Accuracy: 0.9000\n",
      "Epoch 11/20 - Training loss: 0.0961\n",
      "Validation Accuracy: 0.9250\n",
      "Epoch 12/20 - Training loss: 0.0771\n",
      "Validation Accuracy: 0.9000\n",
      "Epoch 13/20 - Training loss: 0.0641\n",
      "Validation Accuracy: 0.9000\n",
      "Epoch 14/20 - Training loss: 0.0591\n",
      "Validation Accuracy: 0.9000\n",
      "Epoch 15/20 - Training loss: 0.0554\n",
      "Validation Accuracy: 0.9000\n",
      "Epoch 16/20 - Training loss: 0.0481\n",
      "Validation Accuracy: 0.9000\n",
      "Epoch 17/20 - Training loss: 0.0434\n",
      "Validation Accuracy: 0.9000\n",
      "Epoch 18/20 - Training loss: 0.0388\n",
      "Validation Accuracy: 0.9000\n",
      "Epoch 19/20 - Training loss: 0.0384\n",
      "Validation Accuracy: 0.9000\n",
      "Epoch 20/20 - Training loss: 0.0343\n",
      "Validation Accuracy: 0.9000\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Training Loop\n",
    "epochs = 20\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Training loss: {total_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    preds, trues = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            pred = torch.argmax(outputs.logits, dim=1)\n",
    "            preds.extend(pred.cpu().numpy())\n",
    "            trues.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(trues, preds)\n",
    "    print(f\"Validation Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bert_roberta_absa_manual\\\\tokenizer_config.json',\n",
       " 'bert_roberta_absa_manual\\\\special_tokens_map.json',\n",
       " 'bert_roberta_absa_manual\\\\vocab.json',\n",
       " 'bert_roberta_absa_manual\\\\merges.txt',\n",
       " 'bert_roberta_absa_manual\\\\added_tokens.json')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"bert_roberta_absa_manual\")\n",
    "tokenizer.save_pretrained(\"bert_roberta_absa_manual\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Validation Accuracy: 0.9000\n",
      "\n",
      "📊 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      1.00      1.00        12\n",
      "    Positive       0.81      1.00      0.89        17\n",
      "     Neutral       1.00      0.64      0.78        11\n",
      "\n",
      "    accuracy                           0.90        40\n",
      "   macro avg       0.94      0.88      0.89        40\n",
      "weighted avg       0.92      0.90      0.89        40\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 1. Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f\"\\n✅ Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 2. Detailed Metrics\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=[\"Negative\", \"Positive\", \"Neutral\"]))\n",
    "\n",
    "# 3. Confusion Matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[\"Negative\", \"Positive\", \"Neutral\"],\n",
    "            yticklabels=[\"Negative\", \"Positive\", \"Neutral\"])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"bert_extracted_asp.csv\")  \n",
    "df = df.dropna(subset=['review', 'predicted_aspects'])\n",
    "\n",
    "# Loading fine-tuned model\n",
    "model_path = \"bert_roberta_absa_manual\"\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_path)\n",
    "model.eval()\n",
    "device = torch.device(\"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "def predict_sentiment_score(aspect, review):\n",
    "    text = aspect + \" [SEP] \" + review\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = F.softmax(outputs.logits, dim=1).squeeze().cpu().numpy()\n",
    "    return {\n",
    "        \"negative_score\": float(probs[0]),\n",
    "        \"positive_score\": float(probs[1]),\n",
    "        \"neutral_score\": float(probs[2]),\n",
    "        \"predicted_label\": [\"negative\", \"positive\", \"neutral\"][probs.argmax()]\n",
    "    } \n",
    "\n",
    "\n",
    "\n",
    "results = df.apply(\n",
    "    lambda row: predict_sentiment_score(str(row['predicted_aspects']), str(row['review'])),\n",
    "    axis=1, result_type='expand'\n",
    ")\n",
    "\n",
    "df = pd.concat([df, results], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>userName</th>\n",
       "      <th>userImage</th>\n",
       "      <th>review</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>repliedAt</th>\n",
       "      <th>appVersion</th>\n",
       "      <th>predicted_aspects</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>neutral_score</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>User_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Good</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>18-12-2024 17:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>uber</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.999529</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>User_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nice</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>18-12-2024 17:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>uber</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.999524</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>User_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Very convenient</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.532.10001</td>\n",
       "      <td>18-12-2024 17:09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.532.10001</td>\n",
       "      <td>uber</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.999006</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>User_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Good</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>18-12-2024 17:08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>uber</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.999529</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>User_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>exllence</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>18-12-2024 17:08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.556.10005</td>\n",
       "      <td>uber</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.998845</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19054</th>\n",
       "      <td>19054</td>\n",
       "      <td>User_11999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Very bad experience with this app, booked a sh...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24-11-2024 21:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>experience</td>\n",
       "      <td>0.999190</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19055</th>\n",
       "      <td>19055</td>\n",
       "      <td>User_11999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Very bad experience with this app, booked a sh...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24-11-2024 21:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>app,</td>\n",
       "      <td>0.999213</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19056</th>\n",
       "      <td>19056</td>\n",
       "      <td>User_11999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Very bad experience with this app, booked a sh...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24-11-2024 21:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>problem</td>\n",
       "      <td>0.999217</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19057</th>\n",
       "      <td>19057</td>\n",
       "      <td>User_11999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Very bad experience with this app, booked a sh...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24-11-2024 21:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>application.</td>\n",
       "      <td>0.999197</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19058</th>\n",
       "      <td>19058</td>\n",
       "      <td>User_11999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Very bad experience with this app, booked a sh...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24-11-2024 21:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location</td>\n",
       "      <td>0.999196</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19059 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0    userName  userImage  \\\n",
       "0               0      User_0        NaN   \n",
       "1               1      User_1        NaN   \n",
       "2               2      User_2        NaN   \n",
       "3               3      User_3        NaN   \n",
       "4               4      User_4        NaN   \n",
       "...           ...         ...        ...   \n",
       "19054       19054  User_11999        NaN   \n",
       "19055       19055  User_11999        NaN   \n",
       "19056       19056  User_11999        NaN   \n",
       "19057       19057  User_11999        NaN   \n",
       "19058       19058  User_11999        NaN   \n",
       "\n",
       "                                                  review  score  \\\n",
       "0                                                   Good      5   \n",
       "1                                                   Nice      5   \n",
       "2                                        Very convenient      5   \n",
       "3                                                   Good      4   \n",
       "4                                               exllence      5   \n",
       "...                                                  ...    ...   \n",
       "19054  Very bad experience with this app, booked a sh...      1   \n",
       "19055  Very bad experience with this app, booked a sh...      1   \n",
       "19056  Very bad experience with this app, booked a sh...      1   \n",
       "19057  Very bad experience with this app, booked a sh...      1   \n",
       "19058  Very bad experience with this app, booked a sh...      1   \n",
       "\n",
       "       thumbsUpCount reviewCreatedVersion                at replyContent  \\\n",
       "0                  0          4.556.10005  18-12-2024 17:17          NaN   \n",
       "1                  0          4.556.10005  18-12-2024 17:17          NaN   \n",
       "2                  0          4.532.10001  18-12-2024 17:09          NaN   \n",
       "3                  0          4.556.10005  18-12-2024 17:08          NaN   \n",
       "4                  0          4.556.10005  18-12-2024 17:08          NaN   \n",
       "...              ...                  ...               ...          ...   \n",
       "19054              0                  NaN  24-11-2024 21:44          NaN   \n",
       "19055              0                  NaN  24-11-2024 21:44          NaN   \n",
       "19056              0                  NaN  24-11-2024 21:44          NaN   \n",
       "19057              0                  NaN  24-11-2024 21:44          NaN   \n",
       "19058              0                  NaN  24-11-2024 21:44          NaN   \n",
       "\n",
       "      repliedAt   appVersion predicted_aspects  negative_score  \\\n",
       "0           NaN  4.556.10005              uber        0.000238   \n",
       "1           NaN  4.556.10005              uber        0.000226   \n",
       "2           NaN  4.532.10001              uber        0.000217   \n",
       "3           NaN  4.556.10005              uber        0.000238   \n",
       "4           NaN  4.556.10005              uber        0.000725   \n",
       "...         ...          ...               ...             ...   \n",
       "19054       NaN          NaN        experience        0.999190   \n",
       "19055       NaN          NaN              app,        0.999213   \n",
       "19056       NaN          NaN           problem        0.999217   \n",
       "19057       NaN          NaN      application.        0.999197   \n",
       "19058       NaN          NaN          location        0.999196   \n",
       "\n",
       "       positive_score  neutral_score predicted_label  \n",
       "0            0.999529       0.000233        positive  \n",
       "1            0.999524       0.000250        positive  \n",
       "2            0.999006       0.000777        positive  \n",
       "3            0.999529       0.000233        positive  \n",
       "4            0.000430       0.998845         neutral  \n",
       "...               ...            ...             ...  \n",
       "19054        0.000512       0.000298        negative  \n",
       "19055        0.000483       0.000304        negative  \n",
       "19056        0.000474       0.000308        negative  \n",
       "19057        0.000501       0.000301        negative  \n",
       "19058        0.000502       0.000302        negative  \n",
       "\n",
       "[19059 rows x 16 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"bert_extracted_with_sentiment_score.csv\", index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
